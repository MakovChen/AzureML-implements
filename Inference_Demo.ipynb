{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02ecfbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\M10901K01\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\M10901K01\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\M10901K01\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size, **kwargs):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\"input_shape\": input_shape,\"patch_size\": patch_size,\"num_patches\": num_patches,\"projection_dim\": projection_dim,\"num_heads\": num_heads,\"transformer_units\": transformer_units,\"transformer_layers\": transformer_layers,\"mlp_head_units\": mlp_head_units,})\n",
    "        return config\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(images=images,sizes=[1, self.patch_size, self.patch_size, 1],strides=[1, self.patch_size, self.patch_size, 1],rates=[1, 1, 1, 1],padding=\"VALID\",)\n",
    "        return tf.reshape(patches, [batch_size, -1, patches.shape[-1]])\n",
    "\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim, **kwargs):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(input_dim=num_patches, output_dim=projection_dim)\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\"input_shape\": input_shape,\"patch_size\": patch_size,\"num_patches\": num_patches,\"projection_dim\": projection_dim,\"num_heads\": num_heads,\"transformer_units\": transformer_units,\"transformer_layers\": transformer_layers,\"mlp_head_units\": mlp_head_units,})\n",
    "        return config\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded\n",
    "    \n",
    "def Annotate(image, annotations, true=None):\n",
    "    annotated_image = image.copy()\n",
    "    img = ImageDraw.Draw(annotated_image)\n",
    "    for bounding_box in annotations:\n",
    "        img.rectangle(bounding_box, outline=\"white\", width=3)\n",
    "    if true != None:\n",
    "        img.rectangle(true, outline=\"red\", width=3)\n",
    "    annotated_image.show()\n",
    "    \n",
    "def intersection_over_union(box_predicted, box_truth):\n",
    "    top_x_intersect = max(box_predicted[0], box_truth[0])\n",
    "    top_y_intersect = max(box_predicted[1], box_truth[1])\n",
    "    bottom_x_intersect = min(box_predicted[2], box_truth[2])\n",
    "    bottom_y_intersect = min(box_predicted[3], box_truth[3])\n",
    "    intersection_area = max(0, bottom_x_intersect - top_x_intersect + 1) * max(0, bottom_y_intersect - top_y_intersect + 1)\n",
    "    box_predicted_area = (box_predicted[2] - box_predicted[0] + 1) * (box_predicted[3] - box_predicted[1] + 1)\n",
    "    box_truth_area = (box_truth[2] - box_truth[0] + 1) * (box_truth[3] - box_truth[1] + 1)\n",
    "    return intersection_area / float(box_predicted_area + box_truth_area - intersection_area)\n",
    "\n",
    "model = tf.keras.models.load_model(\"PCBAoI_on_ViT.h5\", custom_objects={'Patches': Patches, 'PatchEncoder': PatchEncoder}, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ceae8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([63, 144, 19, 145], [166, 193, 173, 204])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "   \n",
    "image_size = 224\n",
    "image = tf.keras.utils.load_img('./test_data/JPEGImages/20170314-SPI-AOI-1.jpeg')\n",
    "(w, h) = image.size[:2]\n",
    "image = image.resize((image_size, image_size))\n",
    "root = ET.parse('./test_data/Annotations/20170314-SPI-AOI-1.xml').getroot()\n",
    "for neighbor in root.iter('bndbox'):\n",
    "    xmin, ymin, xmax, ymax = int(neighbor.find('xmin').text), int(neighbor.find('ymin').text), int(neighbor.find('xmax').text), int(neighbor.find('ymax').text)\n",
    "    annot_true = np.array([xmin, ymin, xmax, ymax])\n",
    "    \n",
    "annot_pred = model.predict(np.expand_dims(image, axis=0))[0]\n",
    "pred = [int(annot_pred[0] * image_size), int(annot_pred[1] * image_size), int(annot_pred[2] * image_size), int(annot_pred[3] * image_size)]\n",
    "true = [int(annot_true[0] / w * image_size), int(annot_true[1] / h * image_size), int(annot_true[2] / w * image_size), int(annot_true[3] / h * image_size)]\n",
    "Annotate(image, [pred], true)\n",
    "pred, true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1ad14e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
